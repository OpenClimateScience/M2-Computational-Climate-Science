{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be74f339-99e2-4d63-8a2c-36af922a67e2",
   "metadata": {},
   "source": [
    "# M2.1 - Working with Gridded Climate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91647cb-5949-42d9-b373-b51b9bfb436b",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "- Lorem ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979c87b-18c6-4ca1-84ca-4a9bb63f2180",
   "metadata": {},
   "source": [
    "## Conceptual and computational constraints\n",
    "\n",
    "As computer technology improves and more satellite-based datasets are available, the size, complexity, and frequency of climate data are increasing rapidly. This can lead to two problems for researchers and resources managers looking to use climate data. First, it can be difficult to conceptualize the size and scale of some climate datasets, leading to issues with data and project management (Jain et al. 2022). Second, it can be difficult to process and analyze climate datasets that are sometimes too large to fit into computer memory or too complex for tractable computation.\n",
    "\n",
    "In this lesson, we'll explore how to manage some of these issues. Because we're learning, we'll use a dataset that isn't as large or complex as others we might encounter, but it should serve as a good illustration of more difficult datasets and how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bc6ce-9274-4335-a724-55729604fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import earthaccess\n",
    "\n",
    "auth = earthaccess.login(strategy = 'netrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f21a7-307a-4d56-9751-b943c72c09d6",
   "metadata": {},
   "source": [
    "## Terrestrial water storage time series\n",
    "\n",
    "To gain more experience working with gridded climate data, and particularly a time series of gridded climate data, we'll use a terrestrial water storage (TWS) dataset from the Global Land Data Assimilation System (GLDAS), which is a global version of the NLDAS we are already familiar with.\n",
    "\n",
    "TWS includes all water on and under the land surface, in the form of snowpack, surface streams and reservoirs, and groundwater. [The TWS dataset we'll be working with from GDLAS](https://podaac.jpl.nasa.gov/dataset/TELLUS_GLDAS-NOAH-3.3_TWS-ANOMALY_MONTHLY) has already been converted to *monthly anomalies.*\n",
    "\n",
    "Recall that *anomalies* are one way of representing variability around a long-term mean. They tell us something about how a particular data point (a particular day, month, or year) compares over time; e.g., is this an especially dry year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de943f1-a70a-4bcd-9bf8-89c8e6d4a5cb",
   "metadata": {},
   "source": [
    "### Performing our skills: Handling raw data\n",
    "\n",
    "*We're about to download some raw data! You know what to do.* Create a new folder called `GLDAS` inside the `data_raw` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bfb8d1-4eea-42a2-aac5-1839175fe95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name = 'TELLUS_GLDAS-NOAH-3.3_TWS-ANOMALY_MONTHLY')\n",
    "\n",
    "# About 20 MB in total, which might take 1-2 minutes\n",
    "earthaccess.download(results, 'data_raw/GLDAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f7713-cb61-47be-a0af-e0c77817c3a0",
   "metadata": {},
   "source": [
    "Let's take a look at one of the datasets we just downloaded. Recall that when we use `glob.glob()`, we can easily get a list of files, but they may not be chronological (or even alphanumeric) order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e440e-bfdd-43b2-b0b8-a7c828ad5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('data_raw/GLDAS/*.nc')\n",
    "files.sort()\n",
    "\n",
    "ds = xr.open_dataset(files[0]) # Just the first file\n",
    "ds['TWS_monthly'].plot(cmap = 'RdYlBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcacc9-91cc-492d-89e1-3f2e34369e57",
   "metadata": {},
   "source": [
    "In the above plot, which depicts the TWS anomaly for April 2002, cool colors show a positive TWS anomaly (i.e., more water than usual for April) and warmer colors show a negative TWS anomaly (i.e., less water than usual for April)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d579897-1c3a-4a5e-817f-ab5072b70173",
   "metadata": {},
   "source": [
    "### Getting a TWS time series\n",
    "\n",
    "As we've seen previously, the `xarray` library has a function, `open_mfdataset()` that can be used to open multiple files as a single dataset. The files may represent multiple pieces of a dataset along *any axis;* in this case, each file represents a different part of the time axis. `xarray` can figure out automatically what order the files should go in because netCDF4 files are structured in a way that explicitly defines X, Y, and time axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec8dd3-595a-49b8-9ee4-8a3ad9b6e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tws_anomaly = xr.open_mfdataset('data_raw/GLDAS/*.nc')\n",
    "tws_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199f60f-0122-455c-bb6a-27fcf245bb63",
   "metadata": {},
   "source": [
    "## Thinking about multi-dimensional arrays\n",
    "\n",
    "By using `xarray.open_mfdataset()` to stack multiple files together in a time series, we obtain something new. Each individual file represented essentially a 2D image: the TWS anomaly on a latitude-longitude grid. With multiple image dates stacked together, we obtain a 3D **data cube,** with X (longitude), Y (latitude), and time axes. `xarray` Datasets can show a helpful illustration when we use them inside a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4fae6-28d4-4591-96d1-7bcc64593308",
   "metadata": {},
   "outputs": [],
   "source": [
    "tws_anomaly['TWS_monthly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae8096e-24f8-4b09-bb85-7a815d07ba5d",
   "metadata": {},
   "source": [
    "When analyzing data cubes, we're typically trying to answer one of these questions:\n",
    "\n",
    "1. How does a climate variable in one or more locations vary over time?\n",
    "1. How does a climate variable at a certain time vary over space?\n",
    "1. How does climate variability (variation over time) compare across space?\n",
    "\n",
    "The first two questions don't require a data cube to answer, but we often have to merge different datasets together in order to answer them. We might consider ourselves lucky to start with a data cube, in that case, because we have all of the data in one place. These questions require us to subset or *index* a multi-dimensional array.\n",
    "\n",
    "The third question can only be answered if we start with a data cube; it's a question that requires us to aggregate or *collapse* an axis of our data cube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d1629-1ec6-4def-a64d-60d3fcc30a0f",
   "metadata": {},
   "source": [
    "## Indexing a multi-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75b960-53f2-4dda-8aa7-0ff5b45b0638",
   "metadata": {},
   "source": [
    "## Aggregating along the axis of a multi-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e021c-87d9-4d7e-8d11-af0080f78744",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- Jain S, Mindlin J, Koren G, Gulizia C, Steadman C, Langendijk GS, Osman M, Abid MA, Rao Y, Rabanal V. 2022. [Are we at risk of losing the current generation of climate researchers to data science?](https://doi.org/10.1029/2022AV000676) *AGU Advances.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
