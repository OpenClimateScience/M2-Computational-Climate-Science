{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdebed81-cb5e-4626-b15f-d3a9e5216441",
   "metadata": {},
   "source": [
    "# M2.4 - Processing Long Climate Data Records Concurrently\n",
    "\n",
    "*Part of:* [**Computational Climate Science**](https://github.com/OpenClimateScience/M2-Computational-Climate-Science) | **Previous Lesson** | **Next Lesson**\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "- [Resource limitations in computing](#Resource-limitations-in-computing)\n",
    "  - [CPU-bound problems](#CPU-bound-problems)\n",
    "- [Concurrent processing for large climate datasets](#Concurrent-processing-for-large-climate-datasets)\n",
    "- [Computing PET using Hargreaves equation](#Computing-PET-using-Hargreaves-equation)\n",
    "  - [Computing top-of-atmosphere (TOA) radiation](#Computing-top-of-atmosphere-(TOA)-radiation)\n",
    "  - [Well-documented functions](#Well-documented-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e31ff-0c6a-4471-9de5-ae2870bc764a",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the previous lesson, we discussed how a simple bucket model can be used to quantify the difference between water supply (precipitation) and water loss (potential evapotranspiration or PET). The ratio of these two quantities is also useful as an index of how much of the water loss is replenished by precipitation:\n",
    "$$\n",
    "\\text{Percentage replenished} \\approx 100\\times \\frac{\\text{Precipitation}}{\\text{PET}}\n",
    "$$\n",
    "\n",
    "**The method for calculating PET that we will use is [the Hargreaves method](https://www.fao.org/4/X0490E/x0490e07.htm#minimum%20data%20requirements) (Allen et al. 2000), because it only requires temperature data.** We'll use temperature data from MERRA-2 to calculate PET. Then, we'll use precipitation data from CHIRPS, again, to derive our hydrologic drought index.\n",
    "\n",
    "**While there are many sources of PET data, we're going to calculate PET on our own so that we can get more experience working with large climate datasets.** Along the way, we'll learn how large climate datasets can be processed **concurrently,** which can help to address two common problems:\n",
    "\n",
    "1. The entire dataset is too large to load into memory all at once;\n",
    "2. Data processing can be time-consuming, either because the dataset is so large or because the computations are complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8dbd3d-611a-491a-a502-8054975592a3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resource limitations in computing\n",
    "\n",
    "Generally, the bigger the dataset, the more computational resources are required to analyze it. But exactly what resources are needed depends on both the data and the kind of analysis we want to perform.\n",
    "\n",
    "**In computing problems, there are three major kinds of resource limitations or *bottlenecks,* i.e., limiting factors to running a computer algorithm:**\n",
    "\n",
    "1. **Read and write speed from a file system**\n",
    "2. **Computer memory**\n",
    "3. **Central processing unit (CPU) clock speed (e.g., 3 GHz)**\n",
    "   \n",
    "A bottleneck of **Type 1** occurs when we have either very large datasets or slow file-system read-write speeds. The speed of reading and writing from a file system (or hard disk) depends on the medium; solid-state drives are generally faster than spinning disk hard drives. If the drive is a network attached storage (NAS) device instead of the hard-drive on your computer, then the speed of the network connection is also part of Type 1 bottlenecks. **Problems that are limited by a Type 1 bottleneck are called I/O-Bound (Input/Output-Bound).**\n",
    "\n",
    "A bottleneck of **Type 2** can occur if the dataset is very large and we try to store it all in memory at once, or if our analysis generates too much data in memory. Of course, memory is finite, so data either fits in memory or it doesn't. If our computer program is very sophisticated, it can offload some data stored in memory onto the computer's hard disk. This is called *swapping* and it is extremely slow. Hence, if you are running out of computer memory, your program may not stop due to a lack of memory, but it will slow down severely as it tries to juggle data between memory and hard disk. **Problems that are limited by a Type 2 bottleneck are called Memory-Bound.**\n",
    "\n",
    "A bottleneck of **Type 3** has a lot less to do with the data and more to do with the algorithm we're running. If we're reading in a huge dataset and just doing a simple unit conversion (for example, multiplying the data by 1000 and then saving it back to disk), then CPU clock speed probably isn't an issue: computers can multiply numbers very fast. But exactly how fast depends on how fast the CPU is. **Problems that are limited by a Type 3 bottleneck are called CPU-Bound.**\n",
    "\n",
    "### CPU-bound problems\n",
    "\n",
    "Historically, Type 3 bottlenecks have received the most attention. Improvements in the manufacturing process for CPUs have led to faster and faster chips. Gordon Moore was one of the first to notice the rate of this upward trend, and **Moore's Law** has been an article of faith in the industry for a long time: the tendency for CPU clock speeds to double every 2 years (Moore 1965).\n",
    "\n",
    "[But there are recent signs that this rate of doubling may be slowing down.](https://www.tomshardware.com/tech-industry/semiconductors/intels-ceo-says-moores-law-is-slowing-to-a-three-year-cadence-but-its-not-dead-yet) There are several reasons for this that are beyond the scope of this lesson (Bohr 2007). A major reason is the problem of heat dissipation. Trying to maintain the same rate of growth in transistors has required making transistors smaller. But the smaller they get, the hotter they get when electricity flows through them. Modern chip design is primarily concerned with trying to keep things from melting!\n",
    "\n",
    "However, if we combine multiple low-power CPUs together, we can actually get better performance than from a single, high-power CPU. Consider the figure below. With a single CPU, it is only possible to process data in a Sequential or Concurrent scheme. Sequential processing means that only a single task can be worked on before switching to another task.\n",
    "\n",
    "![](./assets/M2_concurrency.jpg)\n",
    "\n",
    "*Image by [Kevin Wahome](https://kwahome.medium.com/concurrency-is-not-parallelism-a5451d1cde8d)*\n",
    "\n",
    "In a **Concurrent scheme,** computers can seamlessly switch between tasks so fast that it appears as if multiple tasks, or **threads,** are being worked on simultaneously. **Concurrency** or **multi-threading** is how single CPUs have allowed us to do multiple tasks for the first few decades of the personal computer. **To get faster computers and mobile phones today, we are now using multiple, low-power CPUs to work on independent tasks simultaneously.** This is the **Parallel scheme.** \n",
    "\n",
    "**Today, we'll see how multiple CPUs can be used to break a problem down into smaller parts that can be executed simultaneously.** Some of the tools we're working make it so easy to use a Concurrent or Parallel processing scheme that it can be hard to tell the difference between the two. So, in this lesson, we'll use the terms \"Concurrent processing\" or \"Concurrency\" to refer to both the Concurrent and Parallel processing schemes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3fc433-cf29-496a-8394-569ddb943d83",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concurrent processing for large climate datasets\n",
    "\n",
    "As we've seen previously, we can use `earthaccess` to download [MERRA-2](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/) data from NASA EarthData Search. We'll be using the daily, aggregated data we used before, with the `short_name` `\"M2SDNXSLV\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5919795-51a6-46a3-9a3a-6c7ff2c26dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot\n",
    "\n",
    "auth = earthaccess.login()\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name = 'M2SDNXSLV',\n",
    "    temporal = (\"2024-01-01\", \"2024-05-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a970837-b200-4fa4-94b0-22dc21473597",
   "metadata": {},
   "source": [
    "#### &#x1F3AF; Best Practice\n",
    "\n",
    "**Remember: We want to make sure we don't accidentally change our raw data, so these data should be downloaded to a folder reserved for raw data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfa0d2-0be4-4aff-b334-3d70f1fa8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could take about 1 minute on a broadband connection\n",
    "earthaccess.download(results, 'data_raw/MERRA2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a456c07-d7df-4e5b-bc79-b553ff9cf534",
   "metadata": {},
   "source": [
    "Once again, we'll use `xr.open_mfdataset()` to open our collection of files as a single `xarray.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc92eb-03fc-45ae-ae2c-45c6853da409",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset('./data_raw/MERRA2/*2024*.nc4')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f493631-9cf7-458e-9e17-96af0202aced",
   "metadata": {},
   "source": [
    "The MERRA-2 data variables we are interested in are:\n",
    "\n",
    "- `T2MMAX`, the maximum daily temperature (degrees C)\n",
    "- `T2MMEAN`, the mean daily temperature (degrees C)\n",
    "- `T2MMIN`, the minimum daily temperature (degrees C)\n",
    "\n",
    "Note that we have 122 days of data, so the resulting data cube has a time axis of 122 daily time steps. `xarray` has automatically broken our dataset into equal-sized **chunks** that could be processed independently.\n",
    "\n",
    "&#x1F449; In `xarray`, a **chunk** (also called a **block**) is a piece of our dataset: a defined subset along one or more axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63610a8-2d1f-4f01-b806-477800cb934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['T2MMEAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e333b-8b62-438a-bf6b-e4f7394895c0",
   "metadata": {},
   "source": [
    "**The size and shape of the chunks are important if we are going to use concurrency.** Consider, for example, if we wanted to calculate long-term trends. With the chunks we currently have, we could not calculate trends because each chunk contains only one time step.\n",
    "\n",
    "We could try using [the `chunks` argument of `open_mfdataset()`](https://docs.xarray.dev/en/stable/generated/xarray.open_mfdataset.html) to specify that chunks should have 122 elements along the `time` axis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0825fa6-7004-4630-863e-344c29394f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"chunks\" argument tells xarray what size the chunks should be on one or more axes\n",
    "ds = xr.open_mfdataset('./data_raw/MERRA2/*2024*.nc4', chunks = {'time': 122})\n",
    "ds['T2MMEAN'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30601f15-fdde-46a8-b542-fb7767cd4c54",
   "metadata": {},
   "source": [
    "However, it's clear that didn't work; each chunk still only has one time step.\n",
    "\n",
    "#### &#x1F6A9; <span style=\"color:red\">Pay Attention</red>\n",
    "\n",
    "**This is because the `chunks` argument is evaluated separately for each file.** `xr.open_mfdataset()` opens multiple files and combines them into a single dataset but, in this case, because each file represents a different time step, it can't create chunks that span multiple files.\n",
    "\n",
    "Alternatively, we can tell `xarray` how big each chunk should be along the `lat` and `lon` axes, because this doesn't require spanning multiple files. Below, we specify chunk sizes that result in just 4 chunks for every file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ca154-8395-4bc7-849f-8bffd9f46abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset('./data_raw/MERRA2/*2024*.nc4', chunks = {'lat': 182, 'lon': 288})\n",
    "ds['T2MMEAN'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5bcc1-c2fd-4357-8556-acb78131531e",
   "metadata": {},
   "source": [
    "**If we really needed each chunk to contain the entire `time` axis (122 time steps), we would need to re-chunk the data *after* reading in all the files.** We can do this using [the `chunk()` method of an `xarray.Dataset` or `xarray.DataArray`.](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.chunk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7879c-79fa-4397-a5b2-ffdd09aacb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Re-chunking the data *after* loading is generally inefficient, but might be necessary; \n",
    "#    give example of \"what if\" we were interested in calculating trends\n",
    "\n",
    "ds = xr.open_mfdataset('./data_raw/MERRA2/*2024*.nc4')\n",
    "ds = ds.chunk({'time': 122})\n",
    "ds['T2MMEAN'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95989278-6a28-4450-83cd-3ab50638b440",
   "metadata": {},
   "source": [
    "#### &#x1F3AF; Best Practice\n",
    "\n",
    "In general, it's best to use the `chunks` argument because re-chunking the data is inefficient. However, in cases where you need chunks to span multiple files, you will have to re-chunk the data using the `chunk()` method.\n",
    "\n",
    "In this case, we don't actually need chunks to with 122 time steps. We are fine with whatever chunking `xarray` does by default. If we set `chunks = 'auto'`, then `xarray` will choose to load all the input files into memory at once; hence, there is one chunk per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc6d4b-18a9-40c2-9355-75fb79071926",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset('./data_raw/MERRA2/*2024*.nc4', chunks = 'auto')\n",
    "ds['T2MMEAN'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c41e0-cb5b-4f28-9e1f-c2286fd65e27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computing PET using Hargreaves equation\n",
    "\n",
    "In order to calculate the Precipitation-to-PET ratio, we'll first need to use the Hargreaves equation to calculate PET:\n",
    "$$\n",
    "\\text{PET} = 0.0023 \\times R_A \\times \\sqrt{T_{max} - T_{min}} \\times (T + 17.8)\n",
    "$$\n",
    "\n",
    "Above, $R_A$ is the top-of-atmosphere (TOA) solar radiation and $T$, $T_{max}$, and $T_{min}$ are the mean, maximum, and minimum temperatures, respectively.\n",
    "\n",
    "#### &#x1F3AF; Best Practice\n",
    "\n",
    "The Hargreaves equation is just complex enough that we need to develop multiple data-processing steps to get to our goal, which is the Precipitation-to-PET ratio for a defined region. This effort will require that we pay attention to several potential pitfalls of computational data science:\n",
    "\n",
    "- Ensuring that processing steps are done in the correct order, so that data structures and/or Python variables are correctly initialized.\n",
    "- Ensuring that measurement units are correct and compatible between different data processing steps.\n",
    "- Documenting each processing step so that we can identify potential errors and so that a third party can verify or reproduce our analysis.\n",
    "\n",
    "A technique from computer science called **decomposition** can help us to plan our analysis. **Decomposition** involves breaking a problem down into a series of independent, manageable steps. We might decompose our problem into these steps:\n",
    "\n",
    "1. Load the required temperature data inputs.\n",
    "2. Calculate top-of-atmosphere (TOA) solar radiation.\n",
    "3. Calculate potential evapotranspiration (PET) using the Hargreaves equation.\n",
    "4. Compute the Precipitation-to-PET ratio.\n",
    "\n",
    "**These ordered steps should help us to organize our workflow in a way that someone else can easily understand.** We've already loaded the required temperature data (Step 1), so let's move on to calculating TOA radiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00cc7f-c2c2-4a1a-b7ae-a3ebf28f6649",
   "metadata": {},
   "source": [
    "### Computing top-of-atmosphere (TOA) radiation\n",
    "\n",
    "Here is a function for calculating TOA radiation, [based on FAO guidance.](https://www.fao.org/4/X0490E/x0490e07.htm#radiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea17cf3-de5e-45c0-9fa1-eb2bf4ccf171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def toa_radiation(latitude, doy):\n",
    "    '''\n",
    "    Top-of-atmosphere (TOA) radiation for a given latitude (L) and day of year\n",
    "    (DOY) can be calculated as:\n",
    "\n",
    "    R = ((24 * 60) / pi) * G * d * (w * sin(L) * sin(D) + cos(L) * cos(D) * sin(w))\n",
    "\n",
    "    Where G is the solar constant, 0.0820 [MJ m-2 day-1]; d is the (inverse) \n",
    "    relative earth-sun distance; w is the sunset hour angle; and D is the solar\n",
    "    declination angle.\n",
    "    \n",
    "    For more information, consult the FAO documentation:\n",
    "\n",
    "        https://www.fao.org/4/X0490E/x0490e07.htm#radiation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        The latitude on earth, in degrees\n",
    "    doy : int\n",
    "        The day of the year (DOY), an integer on [1,366]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Number\n",
    "        Top-of-atmosphere (TOA) radiation, in [MJ m-2 day-1]\n",
    "    '''\n",
    "    assert isinstance(doy, int), 'The \"doy\" argument must be an integer'\n",
    "    assert doy >= 1 and doy <= 366, 'The \"doy\" argument must be between 1 and 366, inclusive'\n",
    "    solar_constant = 0.0820 # [MJ m-2 day-1]\n",
    "    pi = 3.14159\n",
    "    \n",
    "    # Convert latitude from degrees to radians\n",
    "    latitude_radians = np.deg2rad(latitude)\n",
    "    # Inverse Earth-Sun distance (relative), as a function of day-of-year (DOY)\n",
    "    earth_sun_dist = 1 + 0.0033 * np.cos(doy * ((2 * pi) / 365))\n",
    "    # Solar declination, as a function of DOY\n",
    "    declination = 0.409 * np.sin(doy * ((2 * pi) / 365) - 1.39)\n",
    "    \n",
    "    # Sunset hour angle; we use np.where() below to guard against\n",
    "    #   warnings where arccos() would return invalid values, which\n",
    "    #   happens when the argument is outside [-1, 1]\n",
    "    _hour_angle = -np.tan(latitude_radians) * np.tan(declination)\n",
    "    _hour_angle = np.where(np.abs(_hour_angle) > 1, np.nan, _hour_angle)\n",
    "    sunset_hour_angle = np.arccos(_hour_angle)\n",
    "\n",
    "    # Incident radiation, depends only on the relative earth-sun distance\n",
    "    inc_radiation = ((24 * 60) / pi) * solar_constant * earth_sun_dist\n",
    "    return inc_radiation * (sunset_hour_angle * np.sin(latitude_radians) * np.sin(declination) +\n",
    "            np.cos(latitude_radians) * np.cos(declination) * np.sin(sunset_hour_angle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec80467-d6a5-458c-9ca6-ea653715d1a4",
   "metadata": {},
   "source": [
    "### Well-documented functions\n",
    "\n",
    "**There are several things to note about this function.**\n",
    "\n",
    "There is a **function-level docstring** that provides rich information about the purpose and use of the function. In addition to the important \"Parameters\" and \"Return\" value sections, we have provided a simple, human-readable form of the equation we're using to calculate TOA radiation. We also provided a link to the FAO document where this equation came from. These are all very important things to include so that someone else can figure out how we're calculating TOA radiation. These things also help us to later verify that we're performing calculations correctly.\n",
    "\n",
    "In the **Parameters** section, we made sure to define the measurement units required for each input parameter. This is *extremely* important. In the above example, we would get a different, and incorrect, answer if `latitude` was given in radians instead of degrees. We also indicated the Python **data type,** e.g., `float`. This is also important to include because, when a computation involves the wrong data type, it is often difficult to figure out that the error is due to an incorrect data type.\n",
    "\n",
    "**Variable names** are chosen carefully. We use `latitude` instead of a name like `x`, which is too short and could signify multiple things. We also defined a variable `latitude_radians` to distinguish when we are using latitude in radians, as opposed to degrees. While `latitude` could have been written as `latitude_degrees`, we decided to compromise clarity for a shorter name in this case, although clarity is usually most important. Ultimately, there are some subjective choices to be made, but you should consider choosing variable names that communicate the meaning *and* the measurement units of the quantity they represent. If that is hard to, **inline comments** can help to keep track of units, as we did with the inline comment next to `solar_constant`.\n",
    "\n",
    "**Constants** are defined at the top of our function: `pi` and `solar_constant`. While many people might recognize a number like 3.14 as the number pi, defining it as a variable, `pi`, in our function makes this more clear and allows for us to control the precision of this number in one place. In general, constants should be defined only once!\n",
    "\n",
    "**Comments** are used frequently. In particular, where there are complex calculation steps to obtain the `sunset_hour_angle`, we have a long comment above the code to explain what it does. If we need to use intermediate variables in our calculation, we can use less informative variable names, like `_hour_angle`. In Python, variable names that begin with the underscore, `_`, signal to users that the variable is less important or can be ignored.\n",
    "\n",
    "For long calculations, like the `return` value of our function, it can be helpful to break them up into smaller, more meaningful quantities, paying attention to the order of operations. This is why we defined the `inc_radiation` variable. When a calculation can't be broken down into meaningful parts, it can improve readability to break the equation across multiple lines, as we did by creating a line break after a `+` operation.\n",
    "\n",
    "Finally, note that we included **assertions,** using the `assert` keyword, to help ensure that users call this function correctly. Consider what happens when the wrong data type, or an out-of-range value, is provided for the `doy` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202363b-d0c1-425a-bfa3-f8d0b23568d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa_radiation(36.1, doy = 14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55ad2f-c967-4589-97a4-6743c7b860c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa_radiation(36.1, doy = 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f4f8c7a-5e09-439e-b177-45ebadaa5816",
   "metadata": {},
   "source": [
    "#### &#x1F3C1; Challenge: Writing a well-documented function\n",
    "\n",
    "Now that we've reviewed what makes a well-documented function, **write the function for the next step of our analysis.** The equation below can be used to calculate PET. Write a well-documented Python function called `potential_et()` that returns PET in units of millimeters per day (mm day$^{-1}$).\n",
    "\n",
    "$$\n",
    "\\text{PET} = 0.0023 \\times R_A \\times \\sqrt{T_{max} - T_{min}} \\times (T + 17.8)\n",
    "$$\n",
    "\n",
    "The inputs to the `potential_et()` function are:\n",
    "\n",
    "- $R_A$ is the top-of-atmosphere solar radiation, in mm H$_2$O equivalent per month\n",
    "- $T_{max}$ is the monthly maximum temperature, in degrees C\n",
    "- $T_{min}$ is the monthly minimum temperature, in degrees C\n",
    "- $T$ is the monthly average temperature, in degrees C\n",
    "\n",
    "Expand the cell below to see one solution to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a256345-d59b-4f4d-97a3-ad98748b9d28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def potential_et(toa_radiation, temp_max, temp_min, temp_mean):\n",
    "    '''\n",
    "    Calculates potential evapotranspiration, according to the Hargreaves\n",
    "    equation:\n",
    "\n",
    "    PET = 0.0023 * R * sqrt(Tmax - Tmin) * (Tmean + 17.8)\n",
    "\n",
    "    Where R is the top-of-atmosphere (TOA) radiation (mm month-1); Tmax and \n",
    "    Tmin are the maximum and minimum monthly air temperatures (degrees C),\n",
    "    respectively; and Tmean is monthly mean air temperature (degrees C).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    toa_radiation : Number\n",
    "        The top-of-atmosphere (TOA) radiation (mm day-1)\n",
    "    temp_max : Number\n",
    "        Maximum monthly air temperature (degrees C)\n",
    "    temp_min : Number\n",
    "        Minimum monthly air temperature (degrees C)\n",
    "    temp_mean : Number\n",
    "        Average monthly air temperature (degrees C)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Number\n",
    "        The potential evapotranspiration (PET) in [mm day-1]\n",
    "    '''\n",
    "    return 0.0023 * toa_radiation * np.sqrt(temp_max - temp_min) * (temp_mean + 17.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef552f-545a-4dce-b500-1be8a563b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa_radiation(32, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2c6bf-1d1a-4bb0-ab55-eafb461f9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.array([22, 32, 42])\n",
    "\n",
    "toa_radiation(lats, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e2598-6ba5-49e0-aca9-b18dd34fdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "doy = np.arange(1, 365)\n",
    "\n",
    "rad = toa_radiation(32, doy)\n",
    "pyplot.plot(doy, rad, 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1310e-62f1-43b9-a999-e891c2c8deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Vectorization\n",
    "\n",
    "toa_radiation(lats, doy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea6569-67f2-430f-a6de-31442dc93869",
   "metadata": {},
   "source": [
    "### Deriving variables from `xarray` coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1da3e-95c2-46c0-90c4-426eb5eaa329",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb97188-d6d7-4a8c-a13f-1bdc81d617fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ec0b2-b1d2-4a8c-aeb0-22a002634540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Vectorization\n",
    "# TODO Getting an array of latitude values to match our temperature arrays\n",
    "\n",
    "lats = ds['lat'].values\n",
    "lats = lats.reshape((361, 1)).repeat(ds.lon.size, axis = 1)\n",
    "lats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815ad09-43bd-4b31-b6bf-c6928056e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Have to specify the dimensions of a new variable\n",
    "\n",
    "ds['lat_grid'] = (('lat', 'lon'), lats)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7824b5-9710-4ab0-ab04-bf24463f9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO HOWEVER, it will be much easier to do some computation later\n",
    "#   if our \"lat_grid\" has the same dimensions as all the other Variables\n",
    "\n",
    "lats2 = lats.reshape((361, 576, 1)).repeat(122, axis = 2)\n",
    "lats2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68812f-5f82-470a-ad5e-31b63b231aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['lat_grid'] = (('lat', 'lon', 'time'), lats2)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e61f52-57b4-4e53-816f-154594e76af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO https://docs.xarray.dev/en/stable/user-guide/time-series.html#datetime-components\n",
    "\n",
    "doy = ds['time.dayofyear'].values\n",
    "doy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdce71-53de-4fe7-a125-357b63ee02ce",
   "metadata": {},
   "source": [
    "### Calculating top-of-atmosphere radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904cd204-66f1-4f07-872f-fe4f00ccdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds.sel(time = '2024-05-01')\n",
    "\n",
    "rad = toa_radiation(test['lat_grid'].values, test['time.dayofyear'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883301ed-1ec5-41c9-9811-c7e758790494",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toa_radiation'] = rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c3dd6-d364-472d-8713-38e8757b4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note that we should specify the dimensions of a dataset we add\n",
    "\n",
    "test['toa_radiation'] = (('lat', 'lon', 'time'), rad)\n",
    "test['toa_radiation'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54615e7-6052-4b3a-bb17-f822d986d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(dataset):\n",
    "    return dataset.T2MMIN + dataset.T2MMAX\n",
    "\n",
    "xr.map_blocks(my_function, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880410e3-0c16-4871-b5d3-a1ce15cfbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Lazy evaluation (should be a review from Part 1)\n",
    "# TODO Remind learners that \"blocks\" and \"chunks\" are inter-changeable\n",
    "\n",
    "result = xr.map_blocks(my_function, ds).compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5b601-b0c2-4541-93d2-cc8cba250af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Explain difference between the function below and my_function();\n",
    "#   it's difficult for xarray to figure out what the result looks like\n",
    "\n",
    "def toa_radiation_wrapper(dataset):\n",
    "    return toa_radiation(dataset['lat_grid'], dataset['time.dayofyear'])\n",
    "\n",
    "result = xr.map_blocks(toa_radiation_wrapper, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf0f5c-0146-4696-8d40-ec34b5717d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['time.dayofyear'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd081b-6b2a-46e0-a207-ee9bab1d1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ds['T2MMEAN']\n",
    "template.name = 'toa_radiation'\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e704e07-0c15-4b96-beaa-33dc8627d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xr.map_blocks(toa_radiation_wrapper, ds, template = template)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e9c3c-c4ab-4f54-8fa1-214f92ddf8ea",
   "metadata": {},
   "source": [
    "$R_A$ should be multiplied by 0.408 to convert it from [MJ m-2 day-1] to [mm day-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dc536-b8f9-4ce6-9fb3-d819e2629c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa_result = result.compute()\n",
    "\n",
    "# Converting TOA Radiation from [MJ m-2 day-1] to [mm H2O day-1]\n",
    "ds['toa_radiation'] = toa_result * 0.408\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7705f2-dbf1-41cb-8e3c-ea9da489e841",
   "metadata": {},
   "source": [
    "#### &#x1F3AF; Best Practice\n",
    "\n",
    "**Make sure to include some field-level metadata, in case we end up sharing this dataset with others.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0426b55-ba92-40fc-acd1-d8eb6c1ec2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['toa_radiation'].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463521a-5361-4df9-b56d-be3064e17d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['toa_radiation'].attrs['units'] = 'mm H2O day-1'\n",
    "ds['toa_radiation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd561f29-331f-4324-b1e7-e4991edee395",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Profiling computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ac993-b235-4c65-b90a-4c65edbf5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Review computational resources and bottlenecks\n",
    "# TODO Review array and chunk memory sizes\n",
    "\n",
    "ds['T2MMEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d07a0-6ec0-4211-af13-c7521cfecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day = ds.sel(time = '2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a6f33-edbc-4107-a27d-4280615e0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note there is exactly one chunk; i.e., the subsequent computation will not use more than one process\n",
    "\n",
    "first_day['T2MMEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea403c0-cd7b-48a3-ac17-7ebbfaa1bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_et(dataset):\n",
    "    '''\n",
    "    Calculates potential evapotranspiration, according to the Hargreaves\n",
    "    equation:\n",
    "\n",
    "    PET = 0.0023 * R * sqrt(Tmax - Tmin) * (Tmean + 17.8)\n",
    "\n",
    "    Where R is the top-of-atmosphere (TOA) radiation (mm month-1); Tmax and \n",
    "    Tmin are the maximum and minimum monthly air temperatures (degrees C),\n",
    "    respectively; and Tmean is monthly mean air temperature (degrees C).\n",
    "\n",
    "    Single input argument should be an xarray.Dataset with the following\n",
    "    data variables:\n",
    "\n",
    "        T2MMIN: Maximum monthly air temperature (degrees C)\n",
    "        T2MMAX: Minimum monthly air temperature (degrees C)\n",
    "        T2MMEAN: Average monthly air temperature (degrees C)\n",
    "        toa_radiation: The top-of-atmosphere (TOA) radiation (mm day-1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: xarray.Dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Number\n",
    "        The potential evapotranspiration (PET) in [mm day-1]\n",
    "    '''\n",
    "    return 0.0023 * dataset['toa_radiation'] * np.sqrt(dataset['T2MMAX'] - dataset['T2MMIN']) * (dataset['T2MMEAN'] + 17.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76279268-d094-4475-9e55-1c1c406a873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "potential_et(first_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576d65c-5092-4102-92bd-96fcd712df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# TODO Note that we shouldn't try to assign any variables inside a timeit block\n",
    "potential_et(first_day).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbe38d-b5f7-4b67-9b20-9c42ea052969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO About 700 ms for a single day\n",
    "\n",
    "20e-3 * ds.time.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c7bb7-66c5-493b-bfe9-2f25d0ed4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = potential_et(first_day).compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e45e9-2ea4-48a5-a0d7-808331b9f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note that this is really only valid for land surfaces\n",
    "\n",
    "result.name = 'Potential ET (mm day-1)'\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af52a1c-2b9a-4a0c-97a1-8b6d3f910209",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "potential_et(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18503d8c-08b4-4c9e-a830-8a5957bf1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# TODO Discuss how multi-process overhead can cause some concurrent operations to have a longer wall time than expected\n",
    "xr.map_blocks(potential_et, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd01b-e8e5-4116-b592-af0bb569d8dc",
   "metadata": {},
   "source": [
    "Read more about the `timeit` module here:\n",
    "\n",
    "- https://docs.python.org/3/library/timeit.html\n",
    "- https://sjvrijn.github.io/2019/09/28/how-to-timeit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3b55a-8b90-4a4e-81cf-d81ad36dea69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af658ce2-d186-4bcb-b3ae-0063d9de63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet = potential_et(ds)\n",
    "pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5d88c-94c9-4281-9538-834613af454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_tiaret = pet.sel(lon = -1.32, lat = 35.37, method = 'nearest')\n",
    "pet_tiaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918033a7-bb7e-4944-88d2-f6738e6e18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_tiaret.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567d5a0-7786-43ec-aad9-a80b41019809",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps = xr.open_mfdataset('data_raw/CHIRPS/CHIRPS-v2_Africa_monthly_2014-2024.nc')\n",
    "chirps_tiaret = chirps['precip'].sel(x = slice(0.8, 1.8), y = slice(36.1, 35.1))\n",
    "chirps_tiaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45094f3a-246a-4d47-a7cb-0bf13d7c42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Increasing the frequency of our monthly dataset to daily using nearest-neighbor interpolation\n",
    "\n",
    "chirps_tiaret_resampled = chirps_tiaret.isel(time = slice(120, 125)).resample(time = 'D').nearest()\n",
    "chirps_tiaret_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6df090-9efe-4e9f-85e8-b996e3d4df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note that we're using a rough approximation of the number of days in a month\n",
    "\n",
    "chirps_tiaret_daily = chirps_tiaret_resampled.mean(['x', 'y']) / 30\n",
    "chirps_tiaret_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f5a3c-2bac-4556-9edf-bdc76624542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = chirps_tiaret_daily.values / pet_tiaret.values\n",
    "\n",
    "pyplot.figure(figsize = (12, 4))\n",
    "pyplot.plot(pet['time'].values, ratio, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622b544-43ed-46ff-a557-d6977e9ddf99",
   "metadata": {},
   "source": [
    "On its own, the graph above doesn't tell us how severe the drought in Tiaret is. Although precipitation in the region has replenished less than 5% of its lost water over the past few months, this could be part of the normal seasonal cycle. Actually, we know that January through April is a relatively wet period for Tiaret, but the question remains: **Can we compare this year to past years?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904ee41-a9c3-4a5f-b4a4-ab54a9f9c523",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### More resources\n",
    "\n",
    "- The National Center for Atmospheric Research (NCAR) has an excellent article on [\"Using `dask` to scale up your data analysis.\"](https://ncar.github.io/Xarray-Dask-ESDS-2024/notebooks/02-dask-intro.html)\n",
    "- Sander van Rijn's [tutorial on using the `timeit` module.](https://sjvrijn.github.io/2019/09/28/how-to-timeit.html)\n",
    "\n",
    "### References\n",
    "\n",
    "Bohr, Mark. 2007. \"A 30-year retrospective on Dennard's MOSFET scaling paper.\" [https://www.eng.auburn.edu/~agrawvd/COURSE/READING/LOWP/Boh07.pdf](https://www.eng.auburn.edu/~agrawvd/COURSE/READING/LOWP/Boh07.pdf)\n",
    "\n",
    "Moore, Gordon E. 1965. \"Cramming more components onto integrated circuits\" *Electronics Magazine.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
